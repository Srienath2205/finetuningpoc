{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e0509161",
      "metadata": {
        "id": "e0509161"
      },
      "source": [
        "\n",
        "# Fine‑Tuning Generic Pipeline (LoRA / QLoRA) — Colab\n",
        "\n",
        "This notebook:\n",
        "1) Installs dependencies  \n",
        "2) Uploads your zipped project to `/content/project`  \n",
        "3) Reads YAML configs  \n",
        "4) Loads model (Kaggle Models or Hugging Face)  \n",
        "5) Validates dataset  \n",
        "6) Fine‑tunes with **LoRA/QLoRA**  \n",
        "7) Exports adapters + metadata  \n",
        "\n",
        "> **Tip:** If you see organization Drive policy errors, use a personal Gmail or run this on **Kaggle Notebooks**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0a5f9163",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a5f9163",
        "outputId": "561dc096-539c-4ee3-a120-696165484cd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.7/60.7 MB 15.1 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 540.5/540.5 kB 20.1 MB/s eta 0:00:00\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%bash\n",
        "pip -q install kagglehub transformers peft bitsandbytes accelerate datasets pyyaml trl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "62e35435",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62e35435",
        "outputId": "12fc475c-da7a-48cc-e8ef-13d6f08e50d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/project'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 22 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (22/22), 12.88 KiB | 6.44 MiB/s, done.\n",
            "[OK] Project ready at: /content/project\n",
            "Contents: ['docs', 'README.md', 'notebooks', 'configs', '.git', 'data', 'requirements.txt', 'scripts']\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# PROJECT FETCHER (Git mode only; no OAuth, no Drive)\n",
        "# =========================\n",
        "GIT_URL    = \"https://github.com/Srienath2205/finetuningpoc.git\"   # <-- your public repo\n",
        "GIT_BRANCH = \"main\"      # change if you use another branch name\n",
        "GIT_SUBDIR = \"\"          # if your project is nested in a subfolder, set e.g. \"PROJECT_ROOT/\"\n",
        "\n",
        "import os, shutil\n",
        "\n",
        "TARGET = \"/content/project\"\n",
        "!rm -rf \"$TARGET\"\n",
        "if GIT_BRANCH:\n",
        "    !git clone --depth 1 --branch \"$GIT_BRANCH\" \"$GIT_URL\" \"$TARGET\"\n",
        "else:\n",
        "    !git clone --depth 1 \"$GIT_URL\" \"$TARGET\"\n",
        "\n",
        "# If repo content lives in a subfolder, move it up into /content/project\n",
        "if GIT_SUBDIR:\n",
        "    src = os.path.join(TARGET, GIT_SUBDIR)\n",
        "    assert os.path.isdir(src), f\"Subdir '{GIT_SUBDIR}' not found in cloned repo\"\n",
        "    for name in os.listdir(src):\n",
        "        shutil.move(os.path.join(src, name), os.path.join(TARGET, name))\n",
        "    shutil.rmtree(src, ignore_errors=True)\n",
        "\n",
        "# Basic structure checks\n",
        "must_dirs = [\"configs\", \"data\", \"scripts\"]\n",
        "missing = [d for d in must_dirs if not os.path.isdir(os.path.join(TARGET, d))]\n",
        "if missing:\n",
        "    raise RuntimeError(f\"Missing required folders in {TARGET}: {missing}\")\n",
        "\n",
        "print(\"[OK] Project ready at:\", TARGET)\n",
        "print(\"Contents:\", os.listdir(TARGET))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cf644d9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf644d9b",
        "outputId": "c4847d23-5537-4e5c-946f-4f9adf11f4bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"model\": {\n",
            "    \"model_source\": \"kaggle\",\n",
            "    \"model_name\": \"google/gemma-3/pyTorch/gemma-3-1b-it\",\n",
            "    \"quantization\": \"4bit\",\n",
            "    \"device_map\": \"auto\",\n",
            "    \"torch_dtype\": \"bfloat16\"\n",
            "  },\n",
            "  \"train\": null,\n",
            "  \"data\": {\n",
            "    \"train_path\": \"/content/data/train.jsonl\",\n",
            "    \"eval_path\": \"/content/data/eval.jsonl\",\n",
            "    \"schema_path\": \"/content/data/schema.json\",\n",
            "    \"max_train_records\": null,\n",
            "    \"max_eval_records\": null,\n",
            "    \"add_system_prompt\": false,\n",
            "    \"system_prompt\": \"\"\n",
            "  },\n",
            "  \"usecase\": {\n",
            "    \"usecase_name\": \"generic_usecase\",\n",
            "    \"domain\": \"generic\",\n",
            "    \"output_format\": \"free_text\",\n",
            "    \"metrics\": {\n",
            "      \"schema_fidelity\": false,\n",
            "      \"exact_match\": false,\n",
            "      \"rouge\": false,\n",
            "      \"bleu\": false\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os, yaml, json, sys\n",
        "\n",
        "PROJ = \"/content/project\"\n",
        "sys.path.append(os.path.join(PROJ, 'scripts'))\n",
        "\n",
        "cfg_model   = yaml.safe_load(open(os.path.join(PROJ, 'configs/model_config.yaml')))\n",
        "cfg_train   = yaml.safe_load(open(os.path.join(PROJ, 'configs/training_config.yaml')))\n",
        "cfg_data    = yaml.safe_load(open(os.path.join(PROJ, 'configs/dataset_config.yaml')))\n",
        "cfg_usecase = yaml.safe_load(open(os.path.join(PROJ, 'configs/usecase_config.yaml')))\n",
        "\n",
        "cfg = {\n",
        "  'model': cfg_model,\n",
        "  'train': cfg_train,\n",
        "  'data': cfg_data,\n",
        "  'usecase': cfg_usecase\n",
        "}\n",
        "\n",
        "print(json.dumps(cfg, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b2cdbfe4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2cdbfe4",
        "outputId": "0c0a9677-87c0-4ac8-d665-195614fc0b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Kaggle credentials loaded (if provided)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME') or os.environ.get('KAGGLE_USERNAME','')\n",
        "    os.environ['KAGGLE_KEY']      = userdata.get('KAGGLE_KEY') or os.environ.get('KAGGLE_KEY','')\n",
        "    print(\"[OK] Kaggle credentials loaded (if provided)\")\n",
        "except Exception as e:\n",
        "    print(\"Colab userdata API not available — if using Kaggle Notebooks, you can ignore this.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "proj_scripts = \"/content/project/scripts\"\n",
        "if proj_scripts not in sys.path:\n",
        "    sys.path.insert(0, proj_scripts)\n",
        "\n",
        "# quick sanity check\n",
        "print(\"[i] sys.path head:\", sys.path[:3])\n",
        "print(\"[i] scripts exists:\", os.path.isdir(proj_scripts))\n",
        "print(\"[i] prepare_dataset present:\", os.path.isfile(os.path.join(proj_scripts, \"prepare_dataset.py\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT6tDjIdtAiX",
        "outputId": "b942f048-57ce-4f73-a91e-0d0e4419e4de"
      },
      "id": "sT6tDjIdtAiX",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[i] sys.path head: ['/content', '/env/python', '/usr/lib/python312.zip']\n",
            "[i] scripts exists: True\n",
            "[i] prepare_dataset present: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a44a66ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "a44a66ec",
        "outputId": "48d61b83-2468-438b-dc81-2b353195ae4e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'validate_or_raise' from 'prepare_dataset' (/content/project/scripts/prepare_dataset.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3715376639.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprepare_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_or_raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/project/data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'validate_or_raise' from 'prepare_dataset' (/content/project/scripts/prepare_dataset.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from prepare_dataset import validate_or_raise\n",
        "from pathlib import Path\n",
        "import json, os\n",
        "\n",
        "data_dir = \"/content/project/data\"\n",
        "train_path = os.path.join(\n",
        "    data_dir,\n",
        "    Path(cfg[\"data\"][\"train_path\"]).name\n",
        ") if not cfg[\"data\"][\"train_path\"].startswith(\"/content\") else cfg[\"data\"][\"train_path\"]\n",
        "\n",
        "eval_path = os.path.join(\n",
        "    data_dir,\n",
        "    Path(cfg[\"data\"][\"eval_path\"]).name\n",
        ") if not cfg[\"data\"][\"eval_path\"].startswith(\"/content\") else cfg[\"data\"][\"eval_path\"]\n",
        "\n",
        "print(\"[i] Train path:\", train_path)\n",
        "print(\"[i] Eval  path:\", eval_path)\n",
        "\n",
        "validate_or_raise(train_path)\n",
        "validate_or_raise(eval_path)\n",
        "print(\"[OK] Dataset validated\")\n",
        "\n",
        "# Save back into cfg\n",
        "cfg[\"data\"][\"_resolved_train\"] = train_path\n",
        "cfg[\"data\"][\"_resolved_eval\"]  = eval_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d1eda55",
      "metadata": {
        "id": "8d1eda55"
      },
      "outputs": [],
      "source": [
        "\n",
        "from load_model_generic import load_model_and_tokenizer\n",
        "\n",
        "tok, model, model_path = load_model_and_tokenizer(\n",
        "    model_source=cfg['model']['model_source'],\n",
        "    model_name=cfg['model']['model_name'],\n",
        "    quantization=cfg['model'].get('quantization','4bit'),\n",
        "    device_map='auto',\n",
        "    torch_dtype=cfg['model'].get('torch_dtype','bfloat16')\n",
        ")\n",
        "print('[OK] Model loaded from:', model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3afa6e66",
      "metadata": {
        "id": "3afa6e66"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the JSONL files resolved earlier in cfg['data']['_resolved_*']\n",
        "ds = load_dataset(\n",
        "    \"json\",\n",
        "    data_files={\n",
        "        \"train\": cfg[\"data\"][\"_resolved_train\"],\n",
        "        \"eval\":  cfg[\"data\"][\"_resolved_eval\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "def format_example(rec):\n",
        "    \"\"\"\n",
        "    Turn a single record with messages -> a plain supervised example.\n",
        "    Expected input format per line:\n",
        "      {\n",
        "        \"messages\": [\n",
        "          {\"role\": \"user\", \"content\": \"...\"},\n",
        "          {\"role\": \"assistant\", \"content\": \"...\"}\n",
        "        ]\n",
        "      }\n",
        "    \"\"\"\n",
        "    msgs = rec[\"messages\"]\n",
        "    user = next((m[\"content\"] for m in msgs if m[\"role\"] == \"user\"), \"\")\n",
        "    assistant = next((m[\"content\"] for m in msgs if m[\"role\"] == \"assistant\"), \"\")\n",
        "    return f\"<user>\\n{user}\\n</user>\\n<assistant>\\n{assistant}\\n</assistant>\"\n",
        "\n",
        "def formatting_func(batch):\n",
        "    return [format_example(r) for r in batch]\n",
        "\n",
        "print(\"[OK] Formatter ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a31420bf",
      "metadata": {
        "id": "a31420bf"
      },
      "outputs": [],
      "source": [
        "\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "import torch\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/output',\n",
        "    num_train_epochs=cfg['train'].get('epochs', 1),\n",
        "    per_device_train_batch_size=cfg['train'].get('batch_size', 2),\n",
        "    per_device_eval_batch_size=cfg['train'].get('batch_size', 2),\n",
        "    learning_rate=cfg['train'].get('lr', 2e-4),\n",
        "    logging_steps=20,\n",
        "    save_strategy='epoch',\n",
        "    evaluation_strategy='epoch',\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    bf16=torch.cuda.is_available(),\n",
        "    report_to=[]\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tok,\n",
        "    train_dataset=ds['train'],\n",
        "    eval_dataset=ds['eval'],\n",
        "    formatting_func=formatting_func,\n",
        "    max_seq_length=cfg['train'].get('max_seq_length', 1024),\n",
        "    args=training_args,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "print('[OK] Training complete')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fffec986",
      "metadata": {
        "id": "fffec986"
      },
      "outputs": [],
      "source": [
        "\n",
        "from export_adapters import export_adapters\n",
        "\n",
        "export_adapters(\n",
        "    model=model,\n",
        "    usecase_name=cfg['usecase']['usecase_name'],\n",
        "    extra_meta={\n",
        "        'model_source': cfg['model']['model_source'],\n",
        "        'model_name': cfg['model']['model_name'],\n",
        "        'method': cfg['train']['method'],\n",
        "    },\n",
        "    base_dir='/content/adapters'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce87ef2c",
      "metadata": {
        "id": "ce87ef2c"
      },
      "outputs": [],
      "source": [
        "\n",
        "import json, random\n",
        "\n",
        "sample = next(iter(ds['eval']))\n",
        "prompt = sample['messages'][0]['content']\n",
        "\n",
        "inputs = tok(prompt, return_tensors='pt').to(model.device)\n",
        "out = model.generate(**inputs, max_new_tokens=200)\n",
        "print(tok.decode(out[0], skip_special_tokens=True))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}