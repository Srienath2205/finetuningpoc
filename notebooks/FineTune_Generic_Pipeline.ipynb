{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0509161",
   "metadata": {},
   "source": [
    "\n",
    "# Fine‑Tuning Generic Pipeline (LoRA / QLoRA) — Colab\n",
    "\n",
    "This notebook:\n",
    "1) Installs dependencies  \n",
    "2) Uploads your zipped project to `/content/project`  \n",
    "3) Reads YAML configs  \n",
    "4) Loads model (Kaggle Models or Hugging Face)  \n",
    "5) Validates dataset  \n",
    "6) Fine‑tunes with **LoRA/QLoRA**  \n",
    "7) Exports adapters + metadata  \n",
    "\n",
    "> **Tip:** If you see organization Drive policy errors, use a personal Gmail or run this on **Kaggle Notebooks**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash\n",
    "pip -q install kagglehub transformers peft bitsandbytes accelerate datasets pyyaml trl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e35435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PROJECT FETCHER (Git mode only; no OAuth, no Drive)\n",
    "# =========================\n",
    "GIT_URL    = \"https://github.com/<your-username>/<your-repo>.git\"  # <-- set this\n",
    "GIT_BRANCH = \"main\"      # change if you use another branch\n",
    "GIT_SUBDIR = \"\"          # optional: if your project is NOT at repo root, set e.g. \"generic-pipeline/\"\n",
    "\n",
    "import os, shutil, sys\n",
    "\n",
    "TARGET = \"/content/project\"\n",
    "!rm -rf \"$TARGET\"\n",
    "if GIT_BRANCH:\n",
    "    !git clone --depth 1 --branch \"$GIT_BRANCH\" \"$GIT_URL\" \"$TARGET\"\n",
    "else:\n",
    "    !git clone --depth 1 \"$GIT_URL\" \"$TARGET\"\n",
    "\n",
    "# If repo content is inside a subfolder, move it up into /content/project\n",
    "if GIT_SUBDIR:\n",
    "    src = os.path.join(TARGET, GIT_SUBDIR)\n",
    "    assert os.path.isdir(src), f\"Subdir '{GIT_SUBDIR}' not found in cloned repo\"\n",
    "    for name in os.listdir(src):\n",
    "        shutil.move(os.path.join(src, name), os.path.join(TARGET, name))\n",
    "    # optional: remove leftover subdir tree\n",
    "    shutil.rmtree(os.path.join(TARGET, GIT_SUBDIR), ignore_errors=True)\n",
    "\n",
    "# basic structure checks\n",
    "must_dirs = [\"configs\", \"data\", \"scripts\"]\n",
    "missing = [d for d in must_dirs if not os.path.isdir(os.path.join(TARGET, d))]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Missing required folders in {TARGET}: {missing}\")\n",
    "\n",
    "print(\"[OK] Project ready at:\", TARGET)\n",
    "print(\"Contents:\", os.listdir(TARGET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf644d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, yaml, json, sys\n",
    "\n",
    "PROJ = \"/content/project\"\n",
    "sys.path.append(os.path.join(PROJ, 'scripts'))\n",
    "\n",
    "cfg_model   = yaml.safe_load(open(os.path.join(PROJ, 'configs/model_config.yaml')))\n",
    "cfg_train   = yaml.safe_load(open(os.path.join(PROJ, 'configs/training_config.yaml')))\n",
    "cfg_data    = yaml.safe_load(open(os.path.join(PROJ, 'configs/dataset_config.yaml')))\n",
    "cfg_usecase = yaml.safe_load(open(os.path.join(PROJ, 'configs/usecase_config.yaml')))\n",
    "\n",
    "cfg = {\n",
    "  'model': cfg_model,\n",
    "  'train': cfg_train,\n",
    "  'data': cfg_data,\n",
    "  'usecase': cfg_usecase\n",
    "}\n",
    "\n",
    "print(json.dumps(cfg, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cdbfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME') or os.environ.get('KAGGLE_USERNAME','')\n",
    "    os.environ['KAGGLE_KEY']      = userdata.get('KAGGLE_KEY') or os.environ.get('KAGGLE_KEY','')\n",
    "    print(\"[OK] Kaggle credentials loaded (if provided)\")\n",
    "except Exception as e:\n",
    "    print(\"Colab userdata API not available — if using Kaggle Notebooks, you can ignore this.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from prepare_dataset import validate_or_raise\n",
    "from pathlib import Path\n",
    "import json, os\n",
    "\n",
    "data_dir = \"/content/project/data\"\n",
    "train_path = os.path.join(data_dir, Path(cfg['data']['train_path']).name) if not cfg['data']['train_path'].startswith('/content') else cfg['data']['train_path']\n",
    "eval_path  = os.path.join(data_dir, Path(cfg['data']['eval_path']).name)  if not cfg['data']['eval_path'].startswith('/content') else cfg['data']['eval_path']\n",
    "\n",
    "print('[i] Train path:', train_path)\n",
    "print('[i] Eval  path:', eval_path)\n",
    "\n",
    "validate_or_raise(train_path)\n",
    "validate_or_raise(eval_path)\n",
    "print('[OK] Dataset validated')\n",
    "\n",
    "# Save back into cfg\n",
    "cfg['data']['_resolved_train'] = train_path\n",
    "cfg['data']['_resolved_eval'] = eval_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1eda55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from load_model_generic import load_model_and_tokenizer\n",
    "\n",
    "tok, model, model_path = load_model_and_tokenizer(\n",
    "    model_source=cfg['model']['model_source'],\n",
    "    model_name=cfg['model']['model_name'],\n",
    "    quantization=cfg['model'].get('quantization','4bit'),\n",
    "    device_map='auto',\n",
    "    torch_dtype=cfg['model'].get('torch_dtype','bfloat16')\n",
    ")\n",
    "print('[OK] Model loaded from:', model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the JSONL files resolved earlier in cfg['data']['_resolved_*']\n",
    "ds = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\": cfg[\"data\"][\"_resolved_train\"],\n",
    "        \"eval\":  cfg[\"data\"][\"_resolved_eval\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "def format_example(rec):\n",
    "    \"\"\"\n",
    "    Turn a single record with messages -> a plain supervised example.\n",
    "    Expected input format per line:\n",
    "      {\n",
    "        \"messages\": [\n",
    "          {\"role\": \"user\", \"content\": \"...\"},\n",
    "          {\"role\": \"assistant\", \"content\": \"...\"}\n",
    "        ]\n",
    "      }\n",
    "    \"\"\"\n",
    "    msgs = rec[\"messages\"]\n",
    "    user = next((m[\"content\"] for m in msgs if m[\"role\"] == \"user\"), \"\")\n",
    "    assistant = next((m[\"content\"] for m in msgs if m[\"role\"] == \"assistant\"), \"\")\n",
    "    return f\"<user>\\n{user}\\n</user>\\n<assistant>\\n{assistant}\\n</assistant>\"\n",
    "\n",
    "def formatting_func(batch):\n",
    "    return [format_example(r) for r in batch]\n",
    "\n",
    "print(\"[OK] Formatter ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31420bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "import torch\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/content/output',\n",
    "    num_train_epochs=cfg['train'].get('epochs', 1),\n",
    "    per_device_train_batch_size=cfg['train'].get('batch_size', 2),\n",
    "    per_device_eval_batch_size=cfg['train'].get('batch_size', 2),\n",
    "    learning_rate=cfg['train'].get('lr', 2e-4),\n",
    "    logging_steps=20,\n",
    "    save_strategy='epoch',\n",
    "    evaluation_strategy='epoch',\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    bf16=torch.cuda.is_available(),\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tok,\n",
    "    train_dataset=ds['train'],\n",
    "    eval_dataset=ds['eval'],\n",
    "    formatting_func=formatting_func,\n",
    "    max_seq_length=cfg['train'].get('max_seq_length', 1024),\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "print('[OK] Training complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffec986",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from export_adapters import export_adapters\n",
    "\n",
    "export_adapters(\n",
    "    model=model,\n",
    "    usecase_name=cfg['usecase']['usecase_name'],\n",
    "    extra_meta={\n",
    "        'model_source': cfg['model']['model_source'],\n",
    "        'model_name': cfg['model']['model_name'],\n",
    "        'method': cfg['train']['method'],\n",
    "    },\n",
    "    base_dir='/content/adapters'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce87ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json, random\n",
    "\n",
    "sample = next(iter(ds['eval']))\n",
    "prompt = sample['messages'][0]['content']\n",
    "\n",
    "inputs = tok(prompt, return_tensors='pt').to(model.device)\n",
    "out = model.generate(**inputs, max_new_tokens=200)\n",
    "print(tok.decode(out[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
